{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this project, we experimented and tuned many ensemble algorithm in the kaggle Airbnb dataset. We even developped our own voting and stacking algorithms in the process.\n",
    "\n",
    "## Feature Engineering : \n",
    "1. In the 'functions' folder can be found more than 600 lines of helper functions in the file 'functions.py' : \n",
    " - get_cartesian: Converts latitude and longitude arrays into (x,y,z) coordinates\n",
    " - lambda_n : Compute the blending factor using a sigmoid function.\n",
    " - target_encoding: Target encoding using blending factor and accounting for hierarchy.\n",
    " - clean_text: A function to remove stop words and special characters\n",
    " - process_batch : Function to encode a single batch of texts\n",
    " - encode_texts : Function to encode many texts by batches\n",
    " - compare_norm_dist : Compares a series normal distribution and return threshold to remove outliers.\n",
    " - preprocess :  Preprocesses raw file to return a feature matrix X (dataframe) and target values y (dataframe)\n",
    " - scores : Compute MAE, MSE, RMSE, R2 and MAPE scores and plot prediction errors\n",
    " - load_params : load json files containing tuned models' parameters\n",
    " - vote_prediction : Homemade voting algorithm that computes predictions and make a weighted sum or average\n",
    " - stacking_prediction : Homemade stacking algorithm that computes predictions on k-fold to feed a final metamodel (linear regression)\n",
    "2. Target encoding of the fields 'host_id' and 'neighborhood' (+200 categories), with integration of a blending factor function to address underrepresented categories, as suggested by Micci-Barreca (2001).\n",
    "3. One-hot encoding of the other categorical fields.\n",
    "4. Integration of external features through an opendata Airbnb dataset (https://public.opendatasoft.com/explore/dataset/airbnb-listings/table/?refine.city=New+York):\n",
    " - Number of beds\n",
    " - Number of rooms\n",
    " - Number of bathrooms\n",
    " - Square meters\n",
    " - Accommodates\n",
    " - Textual Descriptions \n",
    " - Host Response Rate\n",
    " - Type of bed\n",
    " - etc.\n",
    "5. Encoding Seq2Vec of textual fields using a pretrained NLP model made available in spaCy package, followed by T-SNE embedding in 2-D.\n",
    " - We have made available a separate notebook for that in folder 'seq2vec_tsne'\n",
    "6. Elimination of outliers that are more than 3 standard deviations from the mean of log(log(price)) (double log makes the points closer to a Normal distribution). \n",
    "\n",
    "\n",
    "## Models Experimented and Tuned: \n",
    "\n",
    "We have used all the ensemble models seen in class and have also coded our own algorithms for Voting and Stacking (Two other well-known ensemble techniques) that we compared with sklearn's implementation.\n",
    "\n",
    "Our algorithms seemed to have equal or better performances in a faster time, most notably for Stacking were our implementation slightly differs with sklearn's one.\n",
    "\n",
    "\n",
    "In the folder 'models' can be found individual notebooks detailing the training, hyperparameter tuning approach and the performances pre and post tuning of each models. We computed evaluation metrics for both 'Price' and 'log(Price)' but only kept into account the former, as it is the actual target variable of interest ( log(price) having conceptually no meaning): \n",
    " - decision tree\n",
    " - bagging\n",
    " - random forest\n",
    " - extremely randomized forest\n",
    " - adaboost\n",
    " - catboost\n",
    " - sklearn gradient boosting\n",
    " - sklearn hist gradient boosting\n",
    " - LightGBM\n",
    " - XGBoost\n",
    " - Voting    (Weights tuned with hyperopt)\n",
    " - Stacking\n",
    "\n",
    "We have optimized the hyperparameters of all these models with the hyperopt package, which relies on Bayesian Optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from functions.functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, X_val, y_train, y_test, y_val = preprocess(file_paths_global)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3619, 30)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selected Features\n",
    "selected_features = ['minimum_nights', \n",
    "                     'number_of_reviews', \n",
    "                     'reviews_per_month', \n",
    "                     'calculated_host_listings_count', \n",
    "                     'availability_365',\n",
    "                     'Host Response Rate', \n",
    "                     'Accommodates', \n",
    "                     'Bathrooms', \n",
    "                     'Bedrooms', \n",
    "                     'Beds', \n",
    "                     'Square Feet',\n",
    "                     'recency_last_review' ,\n",
    "                     'last_review_day', \n",
    "                     'last_review_month', \n",
    "                     'last_review_year', \n",
    "                     'room_type_Entire home/apt', \n",
    "                     'room_type_Private room', \n",
    "                     'room_type_Shared room',\n",
    "                     'mean_target_neighbourhood',\n",
    "                     'mean_target_neighbourhood_group',\n",
    "                     'neighbourhood_group_Bronx', \n",
    "                     'neighbourhood_group_Brooklyn',\n",
    "                     'neighbourhood_group_Manhattan',\n",
    "                     'neighbourhood_group_Queens',\n",
    "                     'neighbourhood_group_Staten Island',\n",
    "                     'x', \n",
    "                     'y', \n",
    "                     'z',\n",
    "                     'text_encoding_tsne_1',\n",
    "                     'text_encoding_tsne_2']\n",
    "\n",
    "# Prepare feature matrices\n",
    "X_train_selected = X_train[selected_features]\n",
    "X_test_selected = X_test[selected_features]\n",
    "X_val_selected = X_val[selected_features]\n",
    "\n",
    "X_train_np = X_train_selected.to_numpy()\n",
    "X_test_np = X_test_selected.to_numpy()\n",
    "X_val_np = X_val_selected.to_numpy()\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_np = scaler.fit_transform(X_train_np)\n",
    "X_test_np = scaler.transform(X_test_np)\n",
    "X_val_np = scaler.transform(X_val_np)\n",
    "\n",
    "y_train_np = y_train.to_numpy().flatten()\n",
    "y_test_np = y_test.to_numpy().flatten()\n",
    "y_val_np = y_val.to_numpy().flatten()\n",
    "\n",
    "X_test_selected.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "decision_tree = DecisionTreeRegressor(**load_params('models/saved_models/decision_tree_params.json'))\n",
    "\n",
    "# Bagging\n",
    "bagging = BaggingRegressor(**load_params('models/saved_models/bagging_params.json'))\n",
    "\n",
    "# Random Forest\n",
    "random_forest = RandomForestRegressor(**load_params('models/saved_models/random_forest_params.json'))\n",
    "\n",
    "# Extremely randomized tree\n",
    "extra_forest = ExtraTreesRegressor(**load_params('models/saved_models/extremely_randomized_forest_params.json'))\n",
    "\n",
    "# Adaboost\n",
    "adaboost = AdaBoostRegressor(**load_params('models/saved_models/adaboost_params.json'))\n",
    "\n",
    "# sklearn gradient boosting\n",
    "sk_gb = GradientBoostingRegressor(**load_params('models/saved_models/sk_gradient_boosting_params.json'))\n",
    "\n",
    "# sklearn hist gradient boosting\n",
    "hist_sk_gb = HistGradientBoostingRegressor(**load_params('models/saved_models/sk_hist_gradient_boosting_params.json'))\n",
    "\n",
    "# lgbm\n",
    "lgbm = LGBMRegressor(**load_params('models/saved_models/lgbm_params.json'))\n",
    "\n",
    "# XGBOOST\n",
    "xgb = xg.XGBRegressor(**load_params('models/saved_models/xgb_params.json'))\n",
    "\n",
    "# CatBoost\n",
    "catboost = CatBoostRegressor(**load_params('models/saved_models/catboost_params.json'))\n",
    "\n",
    "# Voting\n",
    "vote_weights = load_params('models/saved_models/vote_params.json')\n",
    "weights_normalized = [w/sum(vote_weights.values()) for w in vote_weights.values()]\n",
    "vote_estimators = [ ('xgb',xgb),('lgbm', lgbm),('hist_sk_gb', hist_sk_gb),('extra_forest', extra_forest),('random_forest', random_forest)]\n",
    "\n",
    "# Stacking (Due to long runtime +5 minutes, we preferred to load the scores directly)\n",
    "# Check stacking notebook in 'models' folder for detailed implementation\n",
    "homemade_stacking_scores = load_params('models/saved_scores/homemade_stacking_scores.json')\n",
    "sk_stacking_scores = load_params('models/saved_scores/sk_stacking_scores.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--- Decision Tree ---\n",
      "\n",
      "R²: 0.47807739666812765\n",
      "MAE: 45.8255977175727\n",
      "MSE: 4669.256527186797\n",
      "RMSE: 68.33195831517487\n",
      "MAPE: 0.3711947323149145\n",
      "error_ratio_rmse: 0.4940511628247337\n",
      "error_ratio_mae: 0.33132651833391724\n",
      "\n",
      "\n",
      "--- Bagging ---\n",
      "\n",
      "R²: 0.5544971901954285\n",
      "MAE: 41.776126217532465\n",
      "MSE: 3985.5850068201553\n",
      "RMSE: 63.13148981942494\n",
      "MAPE: 0.3321188897694259\n",
      "error_ratio_rmse: 0.45645093050433105\n",
      "error_ratio_mae: 0.30204818133393396\n",
      "\n",
      "\n",
      "--- Random Forest ---\n",
      "\n",
      "R²: 0.5627451113355987\n",
      "MAE: 41.07743077885374\n",
      "MSE: 3911.796940594226\n",
      "RMSE: 62.54435978243143\n",
      "MAPE: 0.32214093099511787\n",
      "error_ratio_rmse: 0.4522058849259789\n",
      "error_ratio_mae: 0.2969964997715909\n",
      "\n",
      "\n",
      "--- Extremely Randomized Forest ---\n",
      "\n",
      "R²: 0.5617499201528038\n",
      "MAE: 41.06960290091395\n",
      "MSE: 3920.700181987488\n",
      "RMSE: 62.61549474361349\n",
      "MAPE: 0.325223859631188\n",
      "error_ratio_rmse: 0.45272020225502996\n",
      "error_ratio_mae: 0.296939902942026\n",
      "\n",
      "\n",
      "--- Adaboost ---\n",
      "\n",
      "R²: 0.4260360827605809\n",
      "MAE: 48.83235880720346\n",
      "MSE: 5134.831773583393\n",
      "RMSE: 71.65774050012597\n",
      "MAPE: 0.4034292026253855\n",
      "error_ratio_rmse: 0.5180971084743256\n",
      "error_ratio_mae: 0.3530658896221882\n",
      "\n",
      "\n",
      "--- sklearn Gradient Boosting ---\n",
      "\n",
      "R²: 0.5359911869261453\n",
      "MAE: 42.52233386554914\n",
      "MSE: 4151.144566811651\n",
      "RMSE: 64.42937658251593\n",
      "MAPE: 0.3375701698741177\n",
      "error_ratio_rmse: 0.4658348627130693\n",
      "error_ratio_mae: 0.3074433838907072\n",
      "\n",
      "\n",
      "--- sklearn Hist Gradient Boosting ---\n",
      "\n",
      "R²: 0.5590201629240139\n",
      "MAE: 41.26763181495195\n",
      "MSE: 3945.1213062629936\n",
      "RMSE: 62.81020065453536\n",
      "MAPE: 0.3194050595601385\n",
      "error_ratio_rmse: 0.4541279576314544\n",
      "error_ratio_mae: 0.29837168417098087\n",
      "\n",
      "\n",
      "--- LightGBM ---\n",
      "\n",
      "R²: 0.5675034231870559\n",
      "MAE: 40.89373140363327\n",
      "MSE: 3869.227834506519\n",
      "RMSE: 62.203117562599054\n",
      "MAPE: 0.316005849752657\n",
      "error_ratio_rmse: 0.44973864822341775\n",
      "error_ratio_mae: 0.295668323436892\n",
      "\n",
      "\n",
      "--- XGBoost ---\n",
      "\n",
      "R²: 0.5698804077601658\n",
      "MAE: 40.756570707997355\n",
      "MSE: 3847.9627069528105\n",
      "RMSE: 62.03194908233023\n",
      "MAPE: 0.31542625235815186\n",
      "error_ratio_rmse: 0.4485010722955378\n",
      "error_ratio_mae: 0.2946766293183038\n",
      "\n",
      "\n",
      "--- CatBoost ---\n",
      "\n",
      "R²: 0.5648346043803275\n",
      "MAE: 40.90479591232284\n",
      "MSE: 3893.1037876720716\n",
      "RMSE: 62.39474166684298\n",
      "MAPE: 0.3169895341922205\n",
      "error_ratio_rmse: 0.45112412163675525\n",
      "error_ratio_mae: 0.29574832163274284\n",
      "\n",
      "--- Homemade Voting ---\n",
      "\n",
      "\n",
      "R²: 0.5732510782371074\n",
      "MAE: 40.506391661338164\n",
      "MSE: 3817.8078046263286\n",
      "RMSE: 61.78841157228699\n",
      "MAPE: 0.3143592027174954\n",
      "error_ratio_rmse: 0.4467402565221432\n",
      "error_ratio_mae: 0.29286779415590064\n",
      "\n",
      "--- Homemade Stacking ---\n",
      "\n",
      "\n",
      "R2 : 0.574005685903686\n",
      "MAE : 40.40949897945306\n",
      "MSE : 3811.056886482252\n",
      "RMSE : 61.733758078398665\n",
      "MAPE : 0.31209301850892385\n",
      "error_ratio_rmse : 0.4463451028799277\n",
      "error_ratio_mae : 0.2921672443204379\n",
      "\n",
      "--- sklearn Stacking ---\n",
      "\n",
      "\n",
      "R2 : 0.5500372782874432\n",
      "MAE : 41.36670545044114\n",
      "MSE : 4025.484548733263\n",
      "RMSE : 63.44670636631395\n",
      "MAPE : 0.31731717761246064\n",
      "error_ratio_rmse : 0.4587299973622397\n",
      "error_ratio_mae : 0.29908800265541446\n"
     ]
    }
   ],
   "source": [
    "all_scores = []\n",
    "model_names = [('Decision Tree',decision_tree),\n",
    "                ('Bagging',bagging),\n",
    "                ('Random Forest',random_forest),\n",
    "                ('Extremely Randomized Forest',extra_forest),\n",
    "                ('Adaboost',adaboost),\n",
    "                ('sklearn Gradient Boosting',sk_gb),\n",
    "                ('sklearn Hist Gradient Boosting',hist_sk_gb),\n",
    "                ('LightGBM',lgbm),\n",
    "                ('XGBoost',xgb),\n",
    "               ('CatBoost', catboost)\n",
    "               ]\n",
    "\n",
    "for i in range(len(model_names)) :\n",
    "    print('')\n",
    "    print('')\n",
    "    print('--- '+model_names[i][0]+' ---')\n",
    "    print('')\n",
    "    model = model_names[i][1]\n",
    "    if model_names[i][0] != 'CatBoost':\n",
    "        model.fit(X_train_np, y_train_np)\n",
    "    else:\n",
    "        model.fit(X_train_np, y_train_np, verbose=False)        \n",
    "    y_pred = np.maximum(0,model.predict(X_test_np))\n",
    "    score = scores(y_test_np,y_pred,plot=False)\n",
    "    score['Model'] = model_names[i][0]\n",
    "    all_scores.append(score)\n",
    "\n",
    "print('')\n",
    "print('--- Homemade Voting ---')\n",
    "print('')\n",
    "print('')\n",
    "\n",
    "y_pred = vote_prediction(vote_estimators,X_train_np,y_train_np,X_test_np, weights_normalized)\n",
    "score = scores(y_test_np,y_pred,plot=False)\n",
    "score['Model'] = 'Homemade Voting'\n",
    "all_scores.append(score)\n",
    "\n",
    "print('')\n",
    "print('--- Homemade Stacking ---')\n",
    "print('')\n",
    "print('')\n",
    "\n",
    "for key in homemade_stacking_scores:\n",
    "    print(key,':', homemade_stacking_scores[key])\n",
    "homemade_stacking_scores['Model'] = 'Homemade stacking'\n",
    "all_scores.append(homemade_stacking_scores)\n",
    "\n",
    "print('')\n",
    "print('--- sklearn Stacking ---')\n",
    "print('')\n",
    "print('')\n",
    "for key in sk_stacking_scores:\n",
    "    print(key,':', sk_stacking_scores[key])\n",
    "sk_stacking_scores['Model'] = 'sklearn Stacking'\n",
    "all_scores.append(sk_stacking_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>R2</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>error_ratio_rmse</th>\n",
       "      <th>error_ratio_mae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Homemade stacking</td>\n",
       "      <td>0.574006</td>\n",
       "      <td>40.409499</td>\n",
       "      <td>3811.056886</td>\n",
       "      <td>61.733758</td>\n",
       "      <td>0.312093</td>\n",
       "      <td>0.446345</td>\n",
       "      <td>0.292167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Homemade Voting</td>\n",
       "      <td>0.573251</td>\n",
       "      <td>40.506392</td>\n",
       "      <td>3817.807805</td>\n",
       "      <td>61.788412</td>\n",
       "      <td>0.314359</td>\n",
       "      <td>0.446740</td>\n",
       "      <td>0.292868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.569880</td>\n",
       "      <td>40.756571</td>\n",
       "      <td>3847.962707</td>\n",
       "      <td>62.031949</td>\n",
       "      <td>0.315426</td>\n",
       "      <td>0.448501</td>\n",
       "      <td>0.294677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.567503</td>\n",
       "      <td>40.893731</td>\n",
       "      <td>3869.227835</td>\n",
       "      <td>62.203118</td>\n",
       "      <td>0.316006</td>\n",
       "      <td>0.449739</td>\n",
       "      <td>0.295668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.564835</td>\n",
       "      <td>40.904796</td>\n",
       "      <td>3893.103788</td>\n",
       "      <td>62.394742</td>\n",
       "      <td>0.316990</td>\n",
       "      <td>0.451124</td>\n",
       "      <td>0.295748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.562745</td>\n",
       "      <td>41.077431</td>\n",
       "      <td>3911.796941</td>\n",
       "      <td>62.544360</td>\n",
       "      <td>0.322141</td>\n",
       "      <td>0.452206</td>\n",
       "      <td>0.296996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Extremely Randomized Forest</td>\n",
       "      <td>0.561750</td>\n",
       "      <td>41.069603</td>\n",
       "      <td>3920.700182</td>\n",
       "      <td>62.615495</td>\n",
       "      <td>0.325224</td>\n",
       "      <td>0.452720</td>\n",
       "      <td>0.296940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sklearn Hist Gradient Boosting</td>\n",
       "      <td>0.559020</td>\n",
       "      <td>41.267632</td>\n",
       "      <td>3945.121306</td>\n",
       "      <td>62.810201</td>\n",
       "      <td>0.319405</td>\n",
       "      <td>0.454128</td>\n",
       "      <td>0.298372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bagging</td>\n",
       "      <td>0.554497</td>\n",
       "      <td>41.776126</td>\n",
       "      <td>3985.585007</td>\n",
       "      <td>63.131490</td>\n",
       "      <td>0.332119</td>\n",
       "      <td>0.456451</td>\n",
       "      <td>0.302048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>sklearn Stacking</td>\n",
       "      <td>0.550037</td>\n",
       "      <td>41.366705</td>\n",
       "      <td>4025.484549</td>\n",
       "      <td>63.446706</td>\n",
       "      <td>0.317317</td>\n",
       "      <td>0.458730</td>\n",
       "      <td>0.299088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sklearn Gradient Boosting</td>\n",
       "      <td>0.535991</td>\n",
       "      <td>42.522334</td>\n",
       "      <td>4151.144567</td>\n",
       "      <td>64.429377</td>\n",
       "      <td>0.337570</td>\n",
       "      <td>0.465835</td>\n",
       "      <td>0.307443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.478077</td>\n",
       "      <td>45.825598</td>\n",
       "      <td>4669.256527</td>\n",
       "      <td>68.331958</td>\n",
       "      <td>0.371195</td>\n",
       "      <td>0.494051</td>\n",
       "      <td>0.331327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adaboost</td>\n",
       "      <td>0.426036</td>\n",
       "      <td>48.832359</td>\n",
       "      <td>5134.831774</td>\n",
       "      <td>71.657741</td>\n",
       "      <td>0.403429</td>\n",
       "      <td>0.518097</td>\n",
       "      <td>0.353066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Model        R2        MAE          MSE  \\\n",
       "11               Homemade stacking  0.574006  40.409499  3811.056886   \n",
       "10                 Homemade Voting  0.573251  40.506392  3817.807805   \n",
       "8                          XGBoost  0.569880  40.756571  3847.962707   \n",
       "7                         LightGBM  0.567503  40.893731  3869.227835   \n",
       "9                         CatBoost  0.564835  40.904796  3893.103788   \n",
       "2                    Random Forest  0.562745  41.077431  3911.796941   \n",
       "3      Extremely Randomized Forest  0.561750  41.069603  3920.700182   \n",
       "6   sklearn Hist Gradient Boosting  0.559020  41.267632  3945.121306   \n",
       "1                          Bagging  0.554497  41.776126  3985.585007   \n",
       "12                sklearn Stacking  0.550037  41.366705  4025.484549   \n",
       "5        sklearn Gradient Boosting  0.535991  42.522334  4151.144567   \n",
       "0                    Decision Tree  0.478077  45.825598  4669.256527   \n",
       "4                         Adaboost  0.426036  48.832359  5134.831774   \n",
       "\n",
       "         RMSE      MAPE  error_ratio_rmse  error_ratio_mae  \n",
       "11  61.733758  0.312093          0.446345         0.292167  \n",
       "10  61.788412  0.314359          0.446740         0.292868  \n",
       "8   62.031949  0.315426          0.448501         0.294677  \n",
       "7   62.203118  0.316006          0.449739         0.295668  \n",
       "9   62.394742  0.316990          0.451124         0.295748  \n",
       "2   62.544360  0.322141          0.452206         0.296996  \n",
       "3   62.615495  0.325224          0.452720         0.296940  \n",
       "6   62.810201  0.319405          0.454128         0.298372  \n",
       "1   63.131490  0.332119          0.456451         0.302048  \n",
       "12  63.446706  0.317317          0.458730         0.299088  \n",
       "5   64.429377  0.337570          0.465835         0.307443  \n",
       "0   68.331958  0.371195          0.494051         0.331327  \n",
       "4   71.657741  0.403429          0.518097         0.353066  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Final_Results = pd.DataFrame(all_scores)\n",
    "Final_Results = Final_Results[['Model','R2','MAE','MSE','RMSE','MAPE','error_ratio_rmse','error_ratio_mae']] \n",
    "Final_Results.sort_values('R2',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "\n",
    "Our homemade stacking and voting algorithms showed the best results on all metrics, with XGBoost completing the top three.\n",
    "\n",
    "sklearn Stacking performed poorly compared to the homemade, most probably due to the fact that the meta feature matrix cannot be appended to the initial features in sklearn's implementation.\n",
    "\n",
    "This project was interesting as it allowed us to experiment and tune many different ensemble techniques and implement several algorithms and feature engineering approaches."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "03306723d88c9fb7e2d96c1da74f103156186c5988cb13ed43a8356b89897714"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
